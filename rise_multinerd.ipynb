{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikotang/rise-multinerd/blob/main/rise_multinerd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n8QkKNfVPey"
      },
      "source": [
        "# Assignment: Research Engineer in Natural Language Processing\n",
        "## RISE Research Institutes of Sweden\n",
        "\n",
        "This notebook finetunes two language models on the English examples in MultiNERD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h6OwI0ugxfQ"
      },
      "source": [
        "## System A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17_a8mjsWI4K"
      },
      "source": [
        "### Installations and imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zX9tuVGe56SC"
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers datasets evaluate seqeval accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r1W5WfcjtQzI"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "import numpy as np\n",
        "import gc\n",
        "import torch\n",
        "from collections import defaultdict\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klTW9ggafGFl"
      },
      "source": [
        "### Pre-process the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTkrsJGPtAYi"
      },
      "outputs": [],
      "source": [
        "# fetch tokenizer and dataset\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "dataset = load_dataset('Babelscape/multinerd')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTUE-rcSBdpt"
      },
      "outputs": [],
      "source": [
        "# filter dataset to only contain English data\n",
        "eng_dataset = dataset.filter(lambda batch: [lang=='en' for lang in batch['lang']], batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "viqf-gZV7vOV"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  '''\n",
        "  Tokenize Dataset or DatasetDict, and set labels for non-first subtokens as -100 to ignore loss calculation.\n",
        "  '''\n",
        "  tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True) # the examples are already split into words\n",
        "  labels = []\n",
        "  for i, label in enumerate(examples['ner_tags']):\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in word_ids:  # Set the special tokens to -100\n",
        "      if word_idx is None:\n",
        "        label_ids.append(-100)\n",
        "      elif word_idx != previous_word_idx:  # Only label the first token of a given word\n",
        "        label_ids.append(label[word_idx])\n",
        "      else:\n",
        "        label_ids.append(-100)\n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  tokenized_inputs['labels'] = labels\n",
        "  return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIRf6JtT8I1n"
      },
      "outputs": [],
      "source": [
        "tokenized_eng = eng_dataset.map(tokenize_and_align_labels, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-B8FjAOzyDU"
      },
      "source": [
        "### Create dataloader and look-up dicts for model and training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8gSLraN28kQe"
      },
      "outputs": [],
      "source": [
        "# set data collator, pads to len(longest example of the batch)\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "unxo0gmSb-JU"
      },
      "outputs": [],
      "source": [
        "# set up look-up dictionaries for the model\n",
        "# label2id dictionary from https://huggingface.co/datasets/Babelscape/multinerd\n",
        "label2id = {\n",
        "  \"O\": 0,\n",
        "  \"B-PER\": 1,\n",
        "  \"I-PER\": 2,\n",
        "  \"B-ORG\": 3,\n",
        "  \"I-ORG\": 4,\n",
        "  \"B-LOC\": 5,\n",
        "  \"I-LOC\": 6,\n",
        "  \"B-ANIM\": 7,\n",
        "  \"I-ANIM\": 8,\n",
        "  \"B-BIO\": 9,\n",
        "  \"I-BIO\": 10,\n",
        "  \"B-CEL\": 11,\n",
        "  \"I-CEL\": 12,\n",
        "  \"B-DIS\": 13,\n",
        "  \"I-DIS\": 14,\n",
        "  \"B-EVE\": 15,\n",
        "  \"I-EVE\": 16,\n",
        "  \"B-FOOD\": 17,\n",
        "  \"I-FOOD\": 18,\n",
        "  \"B-INST\": 19,\n",
        "  \"I-INST\": 20,\n",
        "  \"B-MEDIA\": 21,\n",
        "  \"I-MEDIA\": 22,\n",
        "  \"B-MYTH\": 23,\n",
        "  \"I-MYTH\": 24,\n",
        "  \"B-PLANT\": 25,\n",
        "  \"I-PLANT\": 26,\n",
        "  \"B-TIME\": 27,\n",
        "  \"I-TIME\": 28,\n",
        "  \"B-VEHI\": 29,\n",
        "  \"I-VEHI\": 30,\n",
        "}\n",
        "id2label = {v:k for k,v in label2id.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdY8l8-yfhCt"
      },
      "source": [
        "### Set up evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yREGfLsapWCM"
      },
      "outputs": [],
      "source": [
        "label_list = list(label2id.keys())\n",
        "\n",
        "seqeval = evaluate.load('seqeval')\n",
        "\n",
        "def set_compute_metrics(label_list):\n",
        "  def compute_metrics(p):\n",
        "    nonlocal label_list     # available with python>=3.x\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "      [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "      for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "      [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "      for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "      'precision': results['overall_precision'],\n",
        "      'recall': results['overall_recall'],\n",
        "      'f1': results['overall_f1'],\n",
        "      'accuracy': results['overall_accuracy'],\n",
        "    }\n",
        "  return compute_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUYt4uTKg_Ps"
      },
      "source": [
        "### Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bH6M9QqrzY05"
      },
      "outputs": [],
      "source": [
        "# make space\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# set arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f'./a_results',\n",
        "    num_train_epochs=3,\n",
        "    max_steps=30000,                        # overrides training epochs\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=1000,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=5e-4,\n",
        "    log_level='info',\n",
        "    logging_dir=f'./a_logs',\n",
        "    logging_steps=1000,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=1000,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',      # determine 'best' according to eval loss\n",
        "    greater_is_better=False,\n",
        "    dataloader_drop_last=True,              # stops when what remains is less than a batch when training by steps\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "# load the model\n",
        "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased',\n",
        "                                                        num_labels=len(id2label),\n",
        "                                                        id2label=id2label,\n",
        "                                                        label2id=label2id,\n",
        "                                                        hidden_dropout_prob=0.5,\n",
        "                                                        ).to('cuda')\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_eng['train'],\n",
        "    eval_dataset=tokenized_eng['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=set_compute_metrics(label_list),\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]      # checks 5 more steps before early stopping\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jylbczjphDR1"
      },
      "source": [
        "## System B\n",
        "\n",
        "Train a model that will predict only five entity types and the O tag (I.e. not part of an entity).\n",
        "\n",
        "All\n",
        "examples should thus remain, but entity types not belonging to one of the following five should be set to zero: PERSON(PER), ORGANIZATION(ORG), LOCATION(LOC), DISEASES(DIS),\n",
        "ANIMAL(ANIM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs_6eZ1WhJM7"
      },
      "source": [
        "### Modify dataset labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT8jRd3vh3cz"
      },
      "outputs": [],
      "source": [
        "label_list_B = ['O',\n",
        "    'B-PER',\n",
        "    'I-PER',\n",
        "    'B-ORG',\n",
        "    'I-ORG',\n",
        "    'B-LOC',\n",
        "    'I-LOC',\n",
        "    'B-ANIM',\n",
        "    'I-ANIM',\n",
        "    'B-DIS',\n",
        "    'I-DIS'\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E00cmKrhE8i"
      },
      "outputs": [],
      "source": [
        "# the same label-id correspondence cannot be kept because the training process only allows label ids of range(0:number of classifications)\n",
        "label2id_B = {l:i for i,l in enumerate(label_list_B)}\n",
        "id2label_B = {v:k for k,v in label2id_B.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20dq1FoHnEhi"
      },
      "outputs": [],
      "source": [
        "# map the tokenized dataset to the simpler set of labels\n",
        "\n",
        "# map system A ids to system B ids, set the rest to 0\n",
        "A2B_mapping = defaultdict(lambda:0, {label2id[label]:label2id_B[label] for label in label_list_B})\n",
        "A2B_mapping[-100] = -100        # for special tokens and trailing subtokens of NER entities\n",
        "\n",
        "def apply_mapping(label):\n",
        "  return A2B_mapping[label]\n",
        "\n",
        "def system_B_labels(example):\n",
        "  vmap = np.vectorize(apply_mapping)\n",
        "  for i, tags in enumerate(example['ner_tags']):\n",
        "    example['ner_tags'][i] = vmap(tags)\n",
        "  for i, tags in enumerate(example['labels']):\n",
        "    example['labels'][i] = vmap(tags)\n",
        "  return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5hhrygkt6s0"
      },
      "outputs": [],
      "source": [
        "tokenized_eng_B = tokenized_eng.map(system_B_labels, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE9BcfPctHLx"
      },
      "source": [
        "### Fine-tune system B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ox11pzvQtGcC"
      },
      "outputs": [],
      "source": [
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "training_args_b = TrainingArguments(\n",
        "    output_dir=f'./b_results',\n",
        "    num_train_epochs=3,\n",
        "    max_steps=30000,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=1000,\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=5e-4,\n",
        "    log_level='info',\n",
        "    logging_dir=f'./b_logs',\n",
        "    logging_steps=1000,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=1000,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False,\n",
        "    dataloader_drop_last=True,\n",
        "    disable_tqdm=False\n",
        "    )\n",
        "\n",
        "model_b = AutoModelForTokenClassification.from_pretrained('bert-base-cased',\n",
        "                                                        num_labels=len(id2label_B),\n",
        "                                                        id2label=id2label_B,\n",
        "                                                        label2id=label2id_B,\n",
        "                                                        hidden_dropout_prob=0.5\n",
        "                                                        ).to('cuda')\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_b,\n",
        "    args=training_args_b,\n",
        "    train_dataset=tokenized_eng_B['train'],\n",
        "    eval_dataset=tokenized_eng_B['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=set_compute_metrics(label_list_B),\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgmZztRGjwjV"
      },
      "source": [
        "## Evaluate test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15WFeNce3WhO"
      },
      "outputs": [],
      "source": [
        "# System A\n",
        "\n",
        "test_model = AutoModelForTokenClassification.from_pretrained('./a_results').to('cuda')\n",
        "\n",
        "test_args = TrainingArguments(\n",
        "    output_dir = './a_test',\n",
        "    do_train = False,\n",
        "    do_predict = True,\n",
        "    per_device_eval_batch_size = 64\n",
        ")\n",
        "\n",
        "tester = Trainer(\n",
        "              model = test_model,\n",
        "              args = test_args,\n",
        "              data_collator=data_collator,\n",
        "              compute_metrics = set_compute_metrics(label_list)\n",
        ")\n",
        "\n",
        "a_results = tester.evaluate(eval_dataset=tokenized_eng['test'])\n",
        "print(a_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlbOzihdSpDc"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "with open(f'a_results.json', 'w') as fout:\n",
        "  json.dump(a_results, fout, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBB6bsmS4vpA"
      },
      "outputs": [],
      "source": [
        "# System B\n",
        "\n",
        "test_model = AutoModelForTokenClassification.from_pretrained('./b_results').to('cuda')\n",
        "\n",
        "test_args = TrainingArguments(\n",
        "    output_dir = './b_test',\n",
        "    do_train = False,\n",
        "    do_predict = True,\n",
        "    per_device_eval_batch_size = 64\n",
        ")\n",
        "\n",
        "tester = Trainer(\n",
        "              model = test_model,\n",
        "              args = test_args,\n",
        "              data_collator=data_collator,\n",
        "              compute_metrics = set_compute_metrics(label_list_B)\n",
        ")\n",
        "\n",
        "b_results = tester.evaluate(eval_dataset=tokenized_eng_B['test'])\n",
        "print(b_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8UmZs_rQfYU"
      },
      "outputs": [],
      "source": [
        "# export results\n",
        "with open(f'b_results.json', 'w') as fout:\n",
        "  json.dump(b_results, fout, indent=4)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMpkSGM6ePm5vDCUF84g0fp",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
